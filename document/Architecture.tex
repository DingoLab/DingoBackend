




% Architecture.tex

%%%% Architecture

%%%%%%%%%%%%%%
%%% 导言区
%%%%%%%%%%%%%%

% flag
\makeatletter
\def\@NoStyleChaper{\ralex} % 设置不适用章节
\def\@ARCHDoc{\ralex} % 设置文档标签
\def\@UsingAppendix{\ralex} % 使用附录
\def\@DocType{article}
\def\@DocTypeCTEX{ctexart}
\makeatother

% 导入导言区
\input{Preamble} % Preamble.tex

\title{后端架构}
\author{李约瀚 \\ qinka@live.com \\ DingoLab \\ 14130140331}

\begin{document}
\maketitle
\newpage

%后端宏观架构
\section{后端宏观架构}

此部分将包含处理负载均衡的大致方法、弹性计算的解决方案、后端API与服务程序分割的
策略，其中会有另一个文档详细描述如何测试 Yesod 框架的负载特性。
此外还将会有对整个宏观设计一个小的对可行性的讨论。


\subsection{负载均衡}
\subsubsection{预期目标}
Dingo 的后端的使用人数并不会多，而且这就是个大作业。然而 按着刘西洋教授的号召：代入感，我还是计划提前预留好
应对大量负载的东西。而且放一颗卫星，希望所能完成的负载量能超过一千万。但是从实际来讲，可能一千万的负载量在
绝大多数的情况下是不需要的，甚至有些时候的负载会长时间达到个位数级别。所以，整个负载是基于弹性计算的。
同时在阅读到 灵雀云微信公众号推的一篇文章，有关于微服务的。大致有了这样整个负载的解决方案。
\subsubsection{硬件负载部分}
我需要看门见山的点出，整个负载均衡的处理办法不包括硬件级别的负载均衡，而之所以在这样一部分点出来，是因为要点出为何不使用硬件均衡。

不使用硬件均衡的原因很简单，那就是由于会使用到弹性计算，所以可能、应该用不上，也没有办法去用。
整个负载计划是使用负载均衡软件与、服务注册与Docker。而整个后端是直接使用 容器，而非直接使用物理或虚拟机或传统意义上的云计算。
\subsubsection{负载的组成}
负载的组成有四大部分组成：负载均衡、服务注册、微服务、DockerShip。

负载均衡使用的是多层 Nginx 进行负载均衡。使用 Docker 容器中运行的 Nginx 。而假设对一个标准的容器，我们定义一个标准单位。
定义标准 CPU 单位计算能力$c$，并使得该单位为离散的（即存在两个数值，其之间不存在任何合法数值）。设定函数
$f_{nginx}(c,m)$ 表示对一个 Docker容器“运行” Nginx 镜像，其中的容器所分配的 cpu 资源为 c，内存配大小为 m，
并假定其他参数不影响。这个 Docker 容器，$f_{nginx}$所表示的则是该情况之下 Nginx 的最大负载量。并设 $d_{nginx}(c,m)$ 表示该情况下的延迟。
假设当前的负载量为$a$ 则$\lceil \log_{f_{nginx}(c,m)}a\rceil$ 为此时所需的 Nginx 层数，$\lceil \log_{f_{nginx}(c,m)}a\rceil \times d_{nginx}(c,m)$ 为此时的延迟。对于 单独\footnote{一般来说，Docker 容器中只会运行一种服务} 
运行在 CPU 计算能力为 $c$，内存为$m$的容器中的服务\footnote{取所有服务的平均}，设其最大负载\footnote{设此处最大负载为相对于单负载延迟，延迟降为其延迟的$\frac{6}{5}$时候对应的负载量}为
 $f_{yesod}(c,m)$，并设此时的延迟为$\frac{6}{5} \times d_{yesod}(c,m)$。则最后负载之后整个服务的延迟的平均最大值是$$\lceil \log_{f_{nginx}(c_1,m_1)}a\rceil \times d_{nginx}(c_1,m_1)+\frac{6}{5} \times d_{yesod}(c_2,m_2)$$

服务注册目前还没有具体选定使用那个，但是还是给出了一些限定。
首先服务注册将需要使用 Redis 这样的内存中的数据库，来用做缓存。
同时会需要有注册、Heartbeat、与销毁的 API 以供容器注册、持续与销毁。
同时，能与 Nginx 或者被修改过代码的Nginx 共同工作。同时整个服务注册对于Nginx 的查询
的延时对整个请求的时间影响不会大于 $d_{nginx}(c,m)$。

微服务使得后端的服务能划分成适度的粒度，不仅能解决服务过于庞大复杂所带来的的问题，
同时，关键的一个问题是：对微服务架构对于弹性计算与均衡负载十分友好。
对于划分粒度适当的微服务架构的服务，当对于某一个或某一组的 API 的访问数量较大时，
起可以相对比较容易的增加增加处理这个或该组API 的那个服务模块，对于Docker 我们直接以几乎微小的
代价启动一个新的容器，而不必启动一个庞大的服务进程之类的东西，也没有虚拟机拖沓的启动。
同时不必为少数的API大量访问而增加整个服务。

Docker 还是一个比较新的而十分强的的工具，Docker 是一种虚拟化产品，而非虚拟机。
这就意味着虽然Docker 仅能运行　Linux　程序制作的镜像，然而其效率、大小与性能等方面与物理机的
差别十分小。而不同物理机上的大量的Docker容器可以组成一个大的虚拟网络，方便负载均衡与弹性计算。最关键的是能精确降低成本。

Docker 与微服务在整个服务的热更新中有这很好的友好度。通过服务注册，自动将过期的Docker容器下线，脱离平台，同时在有新的版本的镜像上线到镜像仓库是，一旦需要新增服务实例则能依赖Docker 的机制上线最新的镜像。当允许不同版本的镜像同时在线时，这种热替换能使得与后端服务相紧密贴合的一些部分都不会察觉到版本的更迭。

而对于后端服务于API 的分割主要需要考虑如下内容：
\begin{itemize}
    \item API 访问时的相关度
    \item 热更新是的粘黏度
    \item 业务与逻辑的扩展性
\end{itemize}
如果说传统的服务组织结构是一种固体的结构，那么微服务架构则可以算作一个液体的结构。
可以方便的改变形状，改变多少。API 的访问相关度就定了某几个 API 之间的关联程度，使得相关的API
处于同一容器之中，避免粒度过小。而不相关的API 则可以分开放置，保证一种相对独立干净的状态。
而考虑热更新的粘黏度则是因为在某一API跟新之后，或许会带来其他API 的变化，而导致为应对
此变化而进行更新，最后使得更新变成类似涟漪的状态。而业务与逻辑的扩展则是应对服务于业务的变动带来的不可预知的对不同API 之间的一些影响。

\end{document}